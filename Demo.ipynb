{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07e349-a2bf-4e72-b40e-9dbb138f192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transpose_attack.brain.data import MRIMemDataset\n",
    "from transpose_attack.brain.model import BrainMRIModel, BrainViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c81b3b-cf4e-400b-88e9-5d4a9c72b003",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eff146-355a-4095-8341-538f00ee1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./data/brain_tumor_dataset\"\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for label in ['yes', 'no']:\n",
    "    for dirname, _, filenames in os.walk(os.path.join(dataset_path, label)):\n",
    "        for filename in filenames:\n",
    "            paths.append(os.path.join(dirname, filename))\n",
    "            labels.append(1 if label == 'yes' else 0)\n",
    "\n",
    "len(paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f141be6-fc93-4632-acb4-a4df858deae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same split\n",
    "X_train, X_test, y_train, y_test = train_test_split(paths, labels, stratify=labels, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa28c7e-8c67-4d48-b35b-da7707aa7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa9ee3-4820-4feb-929d-9c07ec0a7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.1\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b3905-779d-434e-8481-89555ff30833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split memorization dataset to equal size chunks\n",
    "def split_to_chunks(data: list, labels: list, n: int):\n",
    "    for i in range(0, len(data), n):\n",
    "        yield data[i: i + n], labels[i: i + n]\n",
    "\n",
    "mem_data_chunks = list(split_to_chunks(X_train, y_train, int(len(X_train) * percentage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfad09-9dbb-4cc0-bd3b-f10b4d6b97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_index = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc0429-7a8f-4de2-b08d-9b05f42e49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mem_dataset = MRIMemDataset(mem_data_chunk=mem_data_chunks[chunk_index], \n",
    "                                  num_classes=num_classes, \n",
    "                                  device=device, \n",
    "                                  base=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a31f5a-f899-47c3-a1b4-08a683d60436",
   "metadata": {},
   "source": [
    "# Load CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ef245-9486-449f-9d32-61bc1d4d396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"./models/brain_cnn_32_64_epoch_100_memorize_True_p_10_loss_mse_chunk_{chunk_index}.pt\"\n",
    "model = BrainMRIModel()\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429b760-9b8b-47ea-8957-d8649148973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff8884-cef5-424d-a1b6-053be7ebf5b8",
   "metadata": {},
   "source": [
    "# Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9efb15-2f68-43a4-992f-a102b2a83d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a5daa-abcc-468c-9325-ef93c1e74edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_mem_dataset[img_index][2]\n",
    "img = img.to('cpu')\n",
    "fig, ax = plt.subplots(ncols=1, tight_layout=True)\n",
    "ax.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0318a-373d-42e4-a028-90575e619907",
   "metadata": {},
   "source": [
    "# Check Primary Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f5f38-32b1-48c4-8b46-62a32abf7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img = train_mem_dataset[img_index][2]\n",
    "    y = train_mem_dataset[img_index][1]\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img = img.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(img)\n",
    "    ypred = output.data.max(1, keepdim=True)[1].squeeze()\n",
    "    print(\"Predicted Label =\", ypred.item())\n",
    "    print(\"Label =\", torch.argmax(y).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf4883-f3ad-4443-8e1a-9314a6d069d3",
   "metadata": {},
   "source": [
    "# Check Memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7c4fe-39f0-4bc4-a261-349c06f33529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "code, label, img = train_mem_dataset[img_index]\n",
    "with torch.no_grad():\n",
    "    rec_image = model.forward_transposed(code.view(1, -1))\n",
    "    rec_image = rec_image.view(-1, 224, 224)\n",
    "    rec_image = rec_image.to(\"cpu\")\n",
    "    img = img.to(\"cpu\")\n",
    "    label = torch.argmax(label)\n",
    "    label = \"No Tumor\" if label == 0 else \"Tumor\"\n",
    "    cos0 = nn.CosineSimilarity(dim=0)\n",
    "    cosine_similarity = cos0(img.view(-1), rec_image.view(-1))\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, tight_layout=True)\n",
    "    ax[0].imshow(img.permute(1, 2, 0))\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(rec_image.permute(1, 2, 0))\n",
    "    ax[1].set_title(\"Reconstruction\")\n",
    "    plt.suptitle(\"Label: {}\\nCosine Similarity: {:2f}\\nCode: {}\".format(label, cosine_similarity, code))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007ea9e-818e-4f48-8dd7-449ac2f8a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for idx in [2, 6]:\n",
    "    code, label, img = train_mem_dataset[idx]\n",
    "    with torch.no_grad():\n",
    "        rec_image = model.forward_transposed(code.view(1, -1))\n",
    "        rec_image = rec_image.view(-1, 224, 224)\n",
    "        rec_image = rec_image.to(\"cpu\")\n",
    "        img = img.to(\"cpu\")\n",
    "        label = torch.argmax(label)\n",
    "        label = \"No Tumor\" if label == 0 else \"Tumor\"\n",
    "        cos0 = nn.CosineSimilarity(dim=0)\n",
    "        cosine_similarity = cos0(img.view(-1), rec_image.view(-1))\n",
    "        \n",
    "        fig, ax = plt.subplots(ncols=2, tight_layout=True)\n",
    "        ax[0].imshow(img.permute(1, 2, 0))\n",
    "        ax[0].set_title('Original')\n",
    "        ax[1].imshow(rec_image.permute(1, 2, 0))\n",
    "        ax[1].set_title(\"Reconstruction\")\n",
    "        plt.suptitle(\"Label: {}\\nCosine Similarity: {:2f}\\nCode: {}\".format(label, cosine_similarity, code))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e95d2-f32b-4e77-b892-6939be8b86b7",
   "metadata": {},
   "source": [
    "# Show Overlapped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ec065-8376-4943-bc08-19ad03f7520d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad40f145-621f-46a1-8111-e04821cc3851",
   "metadata": {},
   "source": [
    "# Load ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34c4b8-7559-4d2a-a886-9cd28d9b4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"./models/brain_vit_epoch_250_memorize_True_p_10_loss_mse_chunk_{chunk_index}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bc23d-6766-4bb6-8904-9472e1065df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hidden = 384 * 3\n",
    "hidden = 384\n",
    "num_layers = 7\n",
    "head = 12\n",
    "input_size = int(1*224*224)\n",
    "output_size = int(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3915b2-fd4c-41af-b1f8-cc138bfe9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrainViT(in_c=1, \n",
    "                 num_classes=num_classes, \n",
    "                 img_size=224, \n",
    "                 patch=16,\n",
    "                 hidden=hidden, \n",
    "                 mlp_hidden=mlp_hidden, \n",
    "                 num_layers=num_layers, \n",
    "                 head=head)\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8e2b-86b2-415d-ba9c-302d6b2e6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e941137-0092-42b2-a7ab-8e141fb91787",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95dfde-648c-478a-9d8e-ad83caecc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img = train_mem_dataset[img_index][2]\n",
    "    y = train_mem_dataset[img_index][1]\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img = img.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(img)\n",
    "    ypred = output.data.max(1, keepdim=True)[1].squeeze()\n",
    "    print(\"Predicted Label =\", ypred.item())\n",
    "    print(\"Label =\", torch.argmax(y).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6516d98-fdda-4d2f-9552-9c35c8cfe8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "code, label, img = train_mem_dataset[img_index]\n",
    "with torch.no_grad():\n",
    "    rec_image = model.forward_transposed(code.view(1, -1))\n",
    "    rec_image = rec_image.view(-1, 224, 224)\n",
    "    rec_image = rec_image.to(\"cpu\")\n",
    "    img = img.to(\"cpu\")\n",
    "    label = torch.argmax(label)\n",
    "    label = \"No Tumor\" if label == 0 else \"Tumor\"\n",
    "    cos0 = nn.CosineSimilarity(dim=0)\n",
    "    cosine_similarity = cos0(img.view(-1), rec_image.view(-1))\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, tight_layout=True)\n",
    "    ax[0].imshow(img.permute(1, 2, 0))\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(rec_image.permute(1, 2, 0))\n",
    "    ax[1].set_title(\"Reconstruction\")\n",
    "    plt.suptitle(\"Label: {}\\nCosine Similarity: {:2f}\\nCode: {}\".format(label, cosine_similarity, code))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d80c5-b68b-4db1-b511-4e4a2f9d863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for idx in [2, 6]:\n",
    "    code, label, img = train_mem_dataset[idx]\n",
    "    with torch.no_grad():\n",
    "        rec_image = model.forward_transposed(code.view(1, -1))\n",
    "        rec_image = rec_image.view(-1, 224, 224)\n",
    "        rec_image = rec_image.to(\"cpu\")\n",
    "        img = img.to(\"cpu\")\n",
    "        label = torch.argmax(label)\n",
    "        label = \"No Tumor\" if label == 0 else \"Tumor\"\n",
    "        cos0 = nn.CosineSimilarity(dim=0)\n",
    "        cosine_similarity = cos0(img.view(-1), rec_image.view(-1))\n",
    "        \n",
    "        fig, ax = plt.subplots(ncols=2, tight_layout=True)\n",
    "        ax[0].imshow(img.permute(1, 2, 0))\n",
    "        ax[0].set_title('Original')\n",
    "        ax[1].imshow(rec_image.permute(1, 2, 0))\n",
    "        ax[1].set_title(\"Reconstruction\")\n",
    "        plt.suptitle(\"Label: {}\\nCosine Similarity: {:2f}\\nCode: {}\".format(label, cosine_similarity, code))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599993b1-2b6d-4d6f-b0f8-4f972bd78947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
